/**
 * éŸ³é¢‘å¤„ç†æ¨¡å—
 * åŸºäº FFmpeg è¿›è¡Œæœ¬åœ°éŸ³é¢‘è½¬æ¢å’Œå¤„ç†
 */

const fs = require('fs');
const path = require('path');
const { spawn } = require('child_process');
const { AudioTranscriptionError } = require('./errors');
const NodeAudioProcessor = require('./nodeAudioProcessor');

class AudioProcessor {
  constructor() {
    this.tempDir = '/tmp';
    this.supportedFormats = ['mp3', 'wav', 'ogg', 'webm'];
    this.nodeProcessor = new NodeAudioProcessor();
    this.useNodeProcessor = true; // ä¼˜å…ˆä½¿ç”¨ Node.js å®ç°
  }

  /**
   * ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
   */
  async downloadAudio(page, audioUrl) {
    if (this.useNodeProcessor) {
      return await this.nodeProcessor.downloadAudio(page, audioUrl);
    }
    
    try {
      console.log(`ğŸµ å¼€å§‹ä¸‹è½½éŸ³é¢‘: ${audioUrl}`);
      
      const response = await page.evaluate(async (url) => {
        const response = await fetch(url);
        if (!response.ok) {
          throw new Error(`HTTP ${response.status}: ${response.statusText}`);
        }
        const arrayBuffer = await response.arrayBuffer();
        return Array.from(new Uint8Array(arrayBuffer));
      }, audioUrl);

      const audioBuffer = Buffer.from(response);
      console.log(`âœ… éŸ³é¢‘ä¸‹è½½å®Œæˆï¼Œå¤§å°: ${audioBuffer.length} bytes`);
      
      return audioBuffer;
    } catch (error) {
      console.error('éŸ³é¢‘ä¸‹è½½å¤±è´¥:', error);
      throw new AudioTranscriptionError(`Failed to download audio: ${error.message}`);
    }
  }

  /**
   * ä½¿ç”¨ FFmpeg å°†éŸ³é¢‘è½¬æ¢ä¸º WAV æ ¼å¼
   */
  async convertToWav(audioBuffer, inputFormat = 'mp3') {
    if (this.useNodeProcessor) {
      return await this.nodeProcessor.convertToWav(audioBuffer, inputFormat);
    }
    
    // å›é€€åˆ°åŸæœ‰å®ç°
    return new Promise((resolve, reject) => {
      const timestamp = Date.now();
      const inputPath = path.join(this.tempDir, `recaptcha_input_${timestamp}.${inputFormat}`);
      const outputPath = path.join(this.tempDir, `recaptcha_output_${timestamp}.wav`);

      try {
        // å†™å…¥ä¸´æ—¶æ–‡ä»¶
        fs.writeFileSync(inputPath, audioBuffer);
        console.log(`ğŸ”„ å¼€å§‹éŸ³é¢‘è½¬æ¢: ${inputFormat} â†’ WAV`);

        // FFmpeg è½¬æ¢å‘½ä»¤
        const ffmpeg = spawn('ffmpeg', [
          '-i', inputPath,           // è¾“å…¥æ–‡ä»¶
          '-ar', '16000',            // é‡‡æ ·ç‡ 16kHz (è¯­éŸ³è¯†åˆ«æ ‡å‡†)
          '-ac', '1',                // å•å£°é“
          '-f', 'wav',               // è¾“å‡ºæ ¼å¼
          '-y',                      // è¦†ç›–è¾“å‡ºæ–‡ä»¶
          outputPath                 // è¾“å‡ºæ–‡ä»¶
        ]);

        let stderr = '';

        ffmpeg.stderr.on('data', (data) => {
          stderr += data.toString();
        });

        ffmpeg.on('close', (code) => {
          // æ¸…ç†è¾“å…¥æ–‡ä»¶
          try {
            fs.unlinkSync(inputPath);
          } catch (e) {}

          if (code === 0) {
            try {
              const wavBuffer = fs.readFileSync(outputPath);
              fs.unlinkSync(outputPath); // æ¸…ç†è¾“å‡ºæ–‡ä»¶
              console.log(`âœ… éŸ³é¢‘è½¬æ¢å®Œæˆï¼ŒWAVå¤§å°: ${wavBuffer.length} bytes`);
              resolve(wavBuffer);
            } catch (error) {
              reject(new AudioTranscriptionError(`Failed to read converted audio: ${error.message}`));
            }
          } else {
            console.error('FFmpeg é”™è¯¯è¾“å‡º:', stderr);
            reject(new AudioTranscriptionError(`FFmpeg conversion failed with code ${code}`));
          }
        });

        ffmpeg.on('error', (error) => {
          // æ¸…ç†æ–‡ä»¶
          try {
            fs.unlinkSync(inputPath);
          } catch (e) {}
          reject(new AudioTranscriptionError(`FFmpeg spawn error: ${error.message}`));
        });

      } catch (error) {
        reject(new AudioTranscriptionError(`Audio conversion setup failed: ${error.message}`));
      }
    });
  }

  /**
   * æœ¬åœ°è¯­éŸ³è¯†åˆ«ï¼ˆä¼˜å…ˆä½¿ç”¨ Node.js Whisper å®ç°ï¼‰
   */
  async transcribeAudio(wavBuffer, language = 'en-US') {
    if (this.useNodeProcessor) {
      try {
        return await this.nodeProcessor.transcribeAudio(wavBuffer, language);
      } catch (error) {
        console.warn('Node.js éŸ³é¢‘å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•:', error.message);
        // ç»§ç»­ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
      }
    }
    
    try {
      console.log(`ğŸ¤ å¼€å§‹æœ¬åœ°è¯­éŸ³è¯†åˆ«ï¼Œè¯­è¨€: ${language}`);
      
      const transcription = await this._transcribeWithLocalSTT(wavBuffer, language);
      
      if (!transcription || transcription.trim().length === 0) {
        throw new AudioTranscriptionError('Transcription result is empty');
      }

      console.log(`âœ… è¯­éŸ³è¯†åˆ«å®Œæˆ: "${transcription}"`);
      return transcription.trim();

    } catch (error) {
      console.error('è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
      throw new AudioTranscriptionError(`Speech recognition failed: ${error.message}`);
    }
  }

  /**
   * æœ¬åœ° STT å®ç°ï¼ˆå ä½ç¬¦ï¼‰
   * å¯ä»¥é›†æˆ Whisper æˆ–å…¶ä»–å¼€æºæ¨¡å‹
   */
  async _transcribeWithLocalSTT(wavBuffer, language) {
    // TODO: é›†æˆæœ¬åœ°è¯­éŸ³è¯†åˆ«æ¨¡å‹
    // ç¤ºä¾‹é›†æˆæ–¹æ¡ˆï¼š
    
    // æ–¹æ¡ˆ1: ä½¿ç”¨ @xenova/transformers (Whisper)
    /*
    const { pipeline } = require('@xenova/transformers');
    const transcriber = await pipeline('automatic-speech-recognition', 'openai/whisper-tiny');
    const result = await transcriber(wavBuffer);
    return result.text;
    */

    // æ–¹æ¡ˆ2: ä½¿ç”¨ Google Speech Recognition (ä½œä¸ºä¸´æ—¶æ–¹æ¡ˆ)
    /*
    const speech = require('@google-cloud/speech');
    const client = new speech.SpeechClient();
    const request = {
      audio: { content: wavBuffer.toString('base64') },
      config: {
        encoding: 'WEBM_OPUS',
        languageCode: language,
      },
    };
    const [response] = await client.recognize(request);
    return response.results?.[0]?.alternatives?.[0]?.transcript || '';
    */

    // ä¸´æ—¶å®ç°ï¼šè¿”å›æ¨¡æ‹Ÿç»“æœ
    console.log('âš ï¸  å½“å‰ä½¿ç”¨æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«ç»“æœ');
    console.log('   è¯·é›†æˆçœŸå®çš„æœ¬åœ° STT æ¨¡å‹ä»¥è·å¾—å®é™…åŠŸèƒ½');
    
    // æ¨¡æ‹Ÿä¸€äº›å¸¸è§çš„ reCAPTCHA éŸ³é¢‘å†…å®¹
    const mockTranscriptions = [
      'seven three nine',
      'two five eight',
      'four one six',
      'nine seven two',
      'three eight five'
    ];
    
    return mockTranscriptions[Math.floor(Math.random() * mockTranscriptions.length)];
  }

  /**
   * æ£€æŸ¥ FFmpeg æ˜¯å¦å¯ç”¨
   */
  async checkFFmpegAvailability() {
    return new Promise((resolve) => {
      const ffmpeg = spawn('ffmpeg', ['-version']);
      
      ffmpeg.on('close', (code) => {
        resolve(code === 0);
      });
      
      ffmpeg.on('error', () => {
        resolve(false);
      });
    });
  }

  /**
   * æ¸…ç†ä¸´æ—¶æ–‡ä»¶
   */
  cleanup() {
    try {
      const files = fs.readdirSync(this.tempDir);
      const recaptchaFiles = files.filter(file => file.startsWith('recaptcha_'));
      
      for (const file of recaptchaFiles) {
        try {
          fs.unlinkSync(path.join(this.tempDir, file));
        } catch (e) {
          // å¿½ç•¥æ¸…ç†é”™è¯¯
        }
      }
    } catch (error) {
      console.warn('ä¸´æ—¶æ–‡ä»¶æ¸…ç†è­¦å‘Š:', error.message);
    }
  }
}

module.exports = AudioProcessor;